{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Learning with K Nearest Neighbors(dataset preparation).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiWGheAoAZmW"
      },
      "source": [
        "# **Machine Learning with K Nearest Neighbors**\n",
        "In this micro-project, we'll use the KNN algorithm to classify instances from a fake dataset into one or the other target class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uifzlN00AV6Y"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uV03JrmA4FZ"
      },
      "source": [
        "# **Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CwLDw9ACB0Z"
      },
      "source": [
        "df = pd.read_csv('data/KNN_Project_Data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMOfLzjcCpSd"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_mqumikC8WL"
      },
      "source": [
        "# **Standardizing the Variables**\n",
        "Because of the type of data we're dealing with, it's important to standardize the variables before training our model. Skewed distribution of variables makes it harder for our model to deal with it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OizB4UcDLAS"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVixpDnJDU4i"
      },
      "source": [
        "scaler = StandardScaler()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aC1zOrUgDWnK"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3F5l-ttlDho7"
      },
      "source": [
        "We don't need to scale the target class, so we'll ignore that during scaler fitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2n6cWyFDeai"
      },
      "source": [
        "scaler.fit(df.drop('TARGET CLASS',axis=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrzfZc1uDziy"
      },
      "source": [
        "Now we'll use the .transform() method to transform the features to a scaled version."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70HFbRAOD1YS"
      },
      "source": [
        "scaled_feats = scaler.transform(df.drop('TARGET CLASS',axis=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiWDrEaeEHwS"
      },
      "source": [
        "#Converting the scaled features to a dataframe\n",
        "scaled_df = pd.DataFrame(scaled_feats)\n",
        "scaled_df.columns =['XVPM', 'GWYH', 'TRAT', 'TLLZ', 'IGGA', 'HYKR', 'EDFS', 'GUUB', 'MGJM',\n",
        "       'JHZC']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sRtx_9qEb9A"
      },
      "source": [
        "scaled_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}